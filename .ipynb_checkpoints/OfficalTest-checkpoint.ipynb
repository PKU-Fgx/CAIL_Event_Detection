{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e14f3fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import jsonlines\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from model import BertCRFForTokenClassification\n",
    "from torch.utils.data import DataLoader, SequentialSampler, TensorDataset\n",
    "\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a38c062",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "pretrained_path = \"/tf/FangGexiang/3.SememeV2/pretrained_model/bert-base-chinese\"\n",
    "pretrained_model_path = \"/tf/FangGexiang/1.CAILED/ModelSaved/OfficalBaselineV1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f21dab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "    \"\"\"\n",
    "        A single training/test example for token classification.\n",
    "        one single sequence of tokens is an example in LEVEN task.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, guid, words, labels):\n",
    "        self.guid = guid\n",
    "        self.words = words\n",
    "        self.labels = labels\n",
    "\n",
    "\n",
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, label_ids):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_ids = label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdcaa8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_examples_from_file(data_dir):\n",
    "    input_data = jsonlines.open(data_dir)\n",
    "    examples = []\n",
    "\n",
    "    for doc in tqdm(input_data, desc=\"[1] Reading Examples from file...\"):\n",
    "        words = [c['tokens'] for c in doc['content']]\n",
    "        labels = [['O']*len(c['tokens']) for c in doc['content']]\n",
    "\n",
    "        for i in range(0, len(words)):\n",
    "            examples.append(InputExample(guid=\"%s-%d\" % (doc['id'], i),\n",
    "                                         words=words[i],\n",
    "                                         labels=labels[i]))\n",
    "\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc3c83e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(\n",
    "    examples,\n",
    "    label_list,\n",
    "    max_seq_length,\n",
    "    tokenizer,\n",
    "    cls_token_at_end=False,\n",
    "    cls_token=\"[CLS]\",\n",
    "    cls_token_segment_id=0,\n",
    "    sep_token=\"[SEP]\",\n",
    "    sep_token_extra=False,\n",
    "    pad_on_left=False,\n",
    "    pad_token=0,\n",
    "    pad_token_segment_id=0,\n",
    "    pad_token_label_id=-100,\n",
    "    sequence_a_segment_id=0,\n",
    "    mask_padding_with_zero=True,\n",
    "    model_name=None\n",
    "):\n",
    "    \"\"\" Loads a data file into a list of `InputBatch`s\n",
    "        `cls_token_at_end` define the location of the CLS token:\n",
    "            - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\n",
    "            - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\n",
    "        `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)\n",
    "    \"\"\"\n",
    "\n",
    "    label_map = {label: i for i, label in enumerate(label_list)}\n",
    "\n",
    "    # my logic in crf_padding requires this check. I create mask for crf by labels==pad_token_label_id to not include it\n",
    "    # in loss and decoding\n",
    "    assert pad_token_label_id not in label_map.values()\n",
    "\n",
    "    features = []\n",
    "    for ex_index, example in enumerate(tqdm(examples, desc=\"[2] Converting Examples to Features\")):\n",
    "\n",
    "        tokens = []\n",
    "        label_ids = []\n",
    "        for word, label in zip(example.words, example.labels):\n",
    "            word_tokens = tokenizer.tokenize(word)\n",
    "            if len(word_tokens) == 0:\n",
    "                word_tokens = ['<UNK>']\n",
    "            tokens.extend(word_tokens)\n",
    "            # Use the real label id for the first token of the word, and padding ids for the remaining tokens\n",
    "            label_ids.extend([label_map[label]] + [pad_token_label_id] * (len(word_tokens) - 1))\n",
    "\n",
    "        # Account for [CLS] and [SEP] with \"- 2\" and with \"- 3\" for RoBERTa.\n",
    "        special_tokens_count = 3 if sep_token_extra else 2\n",
    "        if len(tokens) > max_seq_length - special_tokens_count:\n",
    "            tokens = tokens[:(max_seq_length - special_tokens_count)]\n",
    "            label_ids = label_ids[:(max_seq_length - special_tokens_count)]\n",
    "\n",
    "        '''\n",
    "        The convention in BERT is:\n",
    "        (a) For sequence pairs:\n",
    "         tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
    "         type_ids:   0   0  0    0    0     0       0   0   1  1  1  1   1   1\n",
    "        (b) For single sequences:\n",
    "         tokens:   [CLS] the dog is hairy . [SEP]\n",
    "         type_ids:   0   0   0   0  0     0   0\n",
    "        Where \"type_ids\" are used to indicate whether this is the first\n",
    "        sequence or the second sequence. The embedding vectors for `type=0` and\n",
    "        `type=1` were learned during pre-training and are added to the wordpiece\n",
    "        embedding vector (and position vector). This is not *strictly* necessary\n",
    "        since the [SEP] token unambiguously separates the sequences, but it makes\n",
    "        it easier for the model to learn the concept of sequences.\n",
    "        '''\n",
    "\n",
    "        tokens += [sep_token]\n",
    "        label_ids += [pad_token_label_id]       # [label_map[\"X\"]]\n",
    "\n",
    "        if sep_token_extra:\n",
    "            # roberta uses an extra separator b/w pairs of sentences\n",
    "            tokens += [sep_token]\n",
    "            label_ids += [pad_token_label_id]\n",
    "        segment_ids = [sequence_a_segment_id] * len(tokens)\n",
    "\n",
    "        if cls_token_at_end:\n",
    "            tokens += [cls_token]\n",
    "            label_ids += [pad_token_label_id]\n",
    "            segment_ids += [cls_token_segment_id]\n",
    "        else:\n",
    "            tokens = [cls_token] + tokens\n",
    "            label_ids = [pad_token_label_id] + label_ids\n",
    "            segment_ids = [cls_token_segment_id] + segment_ids\n",
    "\n",
    "        if model_name:\n",
    "            if model_name == 'xlm-roberta-base':\n",
    "                tokenizer = XLMRobertaTokenizer.from_pretrained(model_name)\n",
    "                input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "            elif model_name.startswith('bert'):\n",
    "                tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "                input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "            elif model_name == 'roberta':\n",
    "                tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "                input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        else:\n",
    "            input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "        # tokens are attended to.\n",
    "        input_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding_length = max_seq_length - len(input_ids)\n",
    "        if pad_on_left:\n",
    "            input_ids = ([pad_token] * padding_length) + input_ids\n",
    "            input_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + input_mask\n",
    "            segment_ids = ([pad_token_segment_id] * padding_length) + segment_ids\n",
    "            label_ids = ([pad_token_label_id] * padding_length) + label_ids\n",
    "\n",
    "        else:\n",
    "            input_ids += ([pad_token] * padding_length)\n",
    "            input_mask += ([0 if mask_padding_with_zero else 1] * padding_length)\n",
    "            segment_ids += ([pad_token_segment_id] * padding_length)\n",
    "            label_ids += ([pad_token_label_id] * padding_length)\n",
    "\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "        assert len(label_ids) == max_seq_length\n",
    "\n",
    "        features.append(\n",
    "            InputFeatures(input_ids=input_ids,\n",
    "                          input_mask=input_mask,\n",
    "                          segment_ids=segment_ids,\n",
    "                          label_ids=label_ids))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcbfa715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_cache_examples(tokenizer, labels, pad_token_label_id):\n",
    "    # Load data features from cache or dataset file\n",
    "    cached_features_file = \"/tf/FangGexiang/1.CAILED/Data/Cache/cached_test_stage_1\"\n",
    "    if os.path.exists(cached_features_file):\n",
    "        features = torch.load(cached_features_file)\n",
    "    else:\n",
    "        examples = read_examples_from_file(\"/tf/FangGexiang/1.CAILED/Data/test_stage1.jsonl\")\n",
    "        features = convert_examples_to_features(\n",
    "            examples, \n",
    "            labels, \n",
    "            512,\n",
    "            tokenizer,\n",
    "            cls_token_at_end=False,           # xlnet has a cls token at the end\n",
    "            cls_token=tokenizer.cls_token,\n",
    "            cls_token_segment_id=0,\n",
    "            sep_token=tokenizer.sep_token,\n",
    "            sep_token_extra=False,            # roberta uses an extra separator b/w pairs of sentences\n",
    "            pad_on_left=False,                # pad on the left for xlnet\n",
    "            pad_token=tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0],\n",
    "            pad_token_segment_id=0,\n",
    "            pad_token_label_id=pad_token_label_id\n",
    "        )\n",
    "        torch.save(features, cached_features_file)\n",
    "\n",
    "    # Convert to Tensors and build dataset\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "    all_label_ids = torch.tensor([f.label_ids for f in features], dtype=torch.long)\n",
    "\n",
    "    dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39b74392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, tokenizer, labels, pad_token_label_id):\n",
    "    print(\"正在读取数据...\")\n",
    "    eval_dataset = load_and_cache_examples(tokenizer, labels, pad_token_label_id)\n",
    "\n",
    "    eval_batch_size = 32\n",
    "    # Note that DistributedSampler samples randomly\n",
    "    eval_sampler = SequentialSampler(eval_dataset)\n",
    "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=eval_batch_size)\n",
    "\n",
    "    # Eval!\n",
    "    eval_loss = 0.0\n",
    "    nb_eval_steps = 0\n",
    "    preds = None\n",
    "    out_label_ids = None\n",
    "    model.eval()\n",
    "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            inputs = {\n",
    "                \"input_ids\": batch[0],\n",
    "                \"attention_mask\": batch[1],\n",
    "                \"token_type_ids\": batch[2]\n",
    "            }\n",
    "            best_path = model(pad_token_label_id=pad_token_label_id, **inputs)\n",
    "\n",
    "        inputs.update({\"labels\": batch[3]})\n",
    "        nb_eval_steps += 1\n",
    "        if preds is None:\n",
    "            preds = best_path.detach().cpu().numpy()\n",
    "            out_label_ids = inputs[\"labels\"].detach().cpu().numpy()\n",
    "        else:\n",
    "            preds = np.append(preds, best_path.detach().cpu().numpy(), axis=0)\n",
    "            out_label_ids = np.append(out_label_ids, inputs[\"labels\"].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "    label_map = {i: label for i, label in enumerate(labels)}\n",
    "\n",
    "    preds_list = [[] for _ in range(out_label_ids.shape[0])]\n",
    "\n",
    "    for i in range(out_label_ids.shape[0]):\n",
    "        for j in range(out_label_ids.shape[1]):\n",
    "            if out_label_ids[i, j] != pad_token_label_id:\n",
    "                preds_list[i].append(label_map[preds[i][j]])\n",
    "\n",
    "    return preds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10f01f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = eval(open(\"/tf/FangGexiang/1.CAILED/Data/bio_label.txt\", \"r\").readline())\n",
    "num_labels = len(labels)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_path, use_fast=True)\n",
    "model_config = AutoConfig.from_pretrained(pretrained_model_path, num_labels=num_labels)\n",
    "\n",
    "ner_model = BertCRFForTokenClassification.from_pretrained(pretrained_model_path, config=model_config)\n",
    "ner_model = ner_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53f816bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在读取数据...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   1%|▏         | 139/9681 [00:36<42:06,  3.78it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8f54915136fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mner_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-2cf2819658c2>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, tokenizer, labels, pad_token_label_id)\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0;34m\"token_type_ids\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             }\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mbest_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_token_label_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_token_label_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tf/FangGexiang/1.CAILED/1.Baseline/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, pad_token_label_id)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mcrf_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrf_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_crf_pad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_token_label_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mcrf_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrf_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcrf_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mbest_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrf_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrf_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0mtemp_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcrf_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpad_token_label_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mbest_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpad_crf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrf_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tf/FangGexiang/1.CAILED/1.Baseline/crf.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, feats, mask)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;34m\"\"\" 直接用 __call__ 就是维特比解码出最佳路径 \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mpath_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_viterbi_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0;31m# return path_score, best_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbest_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tf/FangGexiang/1.CAILED/1.Baseline/crf.py\u001b[0m in \u001b[0;36m_viterbi_decode\u001b[0;34m(self, feats, mask)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mback_points\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mpointer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mback_points\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpointer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0mdecode_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpointer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# feili  pointer.detach().view(batch_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0mpath_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mdecode_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predictions = evaluate(ner_model, tokenizer, labels, -100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc80d193",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_test_predictions_file = \"./results.jsonl\"\n",
    "pure_event2id = eval(open(\"/tf/FangGexiang/1.CAILED/Data/label.txt\", \"r\").readline())\n",
    "with open(output_test_predictions_file, \"w\") as writer:\n",
    "    Cnt = 0\n",
    "    levenTypes = list(pure_event2id.keys())\n",
    "    with open(\"/tf/FangGexiang/1.CAILED/Data/test_stage1.jsonl\", \"r\") as fin:\n",
    "        lines = fin.readlines()\n",
    "        for line in tqdm(lines, desc=\"Writing...\"):\n",
    "            doc = json.loads(line)\n",
    "            res = {}\n",
    "            res['id'] = doc['id']\n",
    "            res['predictions'] = []\n",
    "            for mention in doc['candidates']:\n",
    "                if mention['offset'][1] > len(predictions[Cnt + mention['sent_id']]):\n",
    "                    print(len(doc['content'][mention['sent_id']]['tokens']),\n",
    "                          len(predictions[Cnt + mention['sent_id']]))\n",
    "                    res['predictions'].append({\"id\": mention['id'], \"type_id\": 0})\n",
    "                    continue\n",
    "                is_NA = False if predictions[Cnt + mention['sent_id']][mention['offset'][0]].startswith(\n",
    "                    \"B\") else True\n",
    "                if not is_NA:\n",
    "                    Type = predictions[Cnt + mention['sent_id']][mention['offset'][0]][2:]\n",
    "                    for i in range(mention['offset'][0] + 1, mention['offset'][1]):\n",
    "                        if predictions[Cnt + mention['sent_id']][i][2:] != Type:\n",
    "                            is_NA = True\n",
    "                            break\n",
    "                    if not is_NA:\n",
    "                        res['predictions'].append({\"id\": mention['id'], \"type_id\": levenTypes.index(Type)})\n",
    "                if is_NA:\n",
    "                    res['predictions'].append({\"id\": mention['id'], \"type_id\": 0})\n",
    "            writer.write(json.dumps(res) + \"\\n\")\n",
    "            Cnt += len(doc['content'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
